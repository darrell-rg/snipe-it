{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some libraries that we'll need for this process\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# import pyodbc as dbapi\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import Image\n",
    "from IPython import display\n",
    "import requests\n",
    "import os.path\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import requests\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import snipeit\n",
    "# from snipeit import Models\n",
    "\n",
    "server='https://sawpit.app'\n",
    "token='yourtokenhere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load first sheet of excel into a dataframe\n",
    "df = pd.read_excel('Master Inventory - RMJC 4-15-2023.xlsx', index_col=0, sheet_name=0) \n",
    "#extract the unique values of Summary Name which will become the unique models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show first row of xl spreadsheet\n",
    "for index,row in df.iterrows():\n",
    "    print(index,row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summaryToModel(s):\n",
    "    \n",
    "    # we split this string into   \"POC - FOHC - 6x6x10\"\n",
    "    # print(s)\n",
    "    #remove whitespace\n",
    "    s = s.split('-')\n",
    "    species = s[0].strip()\n",
    "    boxedHeart = s[1].strip()\n",
    "    dims = ''\n",
    "    if len(s) > 2:\n",
    "        dims = s[2].strip()\n",
    "    summary = ' - '.join([species,boxedHeart,dims])\n",
    "    # category 2 is heavy timber\n",
    "    manufacturer_id = 1 # 1 is Unknown\n",
    "    if species ==  \"DF\":\n",
    "        manufacturer_id = 2\n",
    "    if species ==  \"POC\":\n",
    "        manufacturer_id = 3\n",
    "    if species ==  \"AYC\":\n",
    "        manufacturer_id = 4\n",
    "    if species ==  \"WRC\":\n",
    "        manufacturer_id = 5\n",
    "    if species ==  \"WO\":\n",
    "        manufacturer_id = 6\n",
    "    d = {\"name\":summary, \"category_id\":2, \"manufacturer_id\":manufacturer_id, \"fieldset_id\":2}\n",
    "    return d\n",
    "\n",
    "\n",
    "#get a list of unique models\n",
    "uniqueModels = list(map(summaryToModel, df[\"Summary Name\"].unique().tolist()))\n",
    "print(len(uniqueModels))\n",
    "pp.pprint(uniqueModels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the unique models to sawpit\n",
    "uploadModels = False\n",
    "if uploadModels:\n",
    "    M = snipeit.Models()\n",
    "    sumRegex = re.compile(r\"(\\w+) - (\\w+) - ([0123456789.x]+)\")\n",
    "    for m in uniqueModels:\n",
    "        summaryMatch = sumRegex.match(m['name'])\n",
    "        if(summaryMatch is None):\n",
    "            #invalid name, skip it\n",
    "            continue\n",
    "        r = M.create(server, token,  json.dumps(m))\n",
    "        if(\"error\" in r):\n",
    "            print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a dict that maps name to model ids\n",
    "M = snipeit.Models()\n",
    "modelsDict = json.loads( M.get(server, token, 5000) )# Using default limit of 5000 for results\n",
    "# pp.pprint(r)\n",
    "\n",
    "# pp.pprint(modelsDict['rows'][1])\n",
    "model_ids = defaultdict() #default of None\n",
    "for row in modelsDict['rows']:\n",
    "    model_ids[row['name']]=row['id']\n",
    "\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a dict that maps company name to company id \n",
    "C = snipeit.Company()\n",
    "companiesDict = json.loads( C.get(server, token) )# Using default limit of 5000 for results\n",
    "# pp.pprint(r)\n",
    "\n",
    "# pp.pprint(modelsDict['rows'][1])\n",
    "company_ids = defaultdict() #default of None\n",
    "for row in companiesDict['rows']:\n",
    "    company_ids[row['name']]=row['id']\n",
    "\n",
    "company_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a dict that maps supplier name to supplier id \n",
    "# S = snipeit.Supplier()\n",
    "# suppliersDict = json.loads( S.get(server, token) )# Using default limit of 5000 for results\n",
    "# pp.pprint(r)\n",
    "\n",
    "# pp.pprint(modelsDict['rows'][1])\n",
    "supplier_ids = defaultdict(lambda: 8,{\n",
    "    'Delson':1,\n",
    "    'Bluelinx':2,\n",
    "    'Rosboro':3,\n",
    "    'Boulder Lumber':4,\n",
    "    'Hull-Oakes':5,\n",
    "    'Customer':6,\n",
    "    'TETW':7,\n",
    "    'Unknown':8,\n",
    "}) \n",
    "\n",
    "supplier_ids['Delson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions needed for upload\n",
    "def strip(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.strip()\n",
    "        if '-' == s: # change dash into blank\n",
    "            return None\n",
    "        return s\n",
    "    return s\n",
    "\n",
    "def formatDate(s):\n",
    "    if isinstance(s, str):\n",
    "        m, d, y = s.strip().split('/')\n",
    "        return y+'-'+m.rjust(2,'0')+'-'+d.rjust(2,'0')\n",
    "    return s\n",
    "\n",
    "def getDims(row):\n",
    "    summary = row['Summary Name']\n",
    "    s = summary.split('-')\n",
    "    species = s[0].strip()\n",
    "    boxedHeart = s[1].strip()\n",
    "    dims = None\n",
    "    if len(s) > 2:\n",
    "        dims = s[2].strip()\n",
    "    return dims\n",
    "\n",
    "def csvToAsset(row):\n",
    "    summary = row['Summary Name']\n",
    "    status_id = 10 #10 is imported, but does not have new label yet\n",
    "    if 'Used' in row['Status']:\n",
    "        status_id = 9\n",
    "    # print(\"supplier \",strip(row['Supplier']),supplier_ids[strip(row['Supplier'])])\n",
    "    d = {\"asset_tag\":row['SRL_OLD'], \n",
    "        \"name\":getDims(row), #We set the name to just the dims to help with sorting \n",
    "        \"serial\":row['SRL_OLD'], \n",
    "        \"status_id\":status_id, \n",
    "        \"model_id\": model_ids[summary], \n",
    "        \"company_id\": company_ids[strip(row['Inventory'])], \n",
    "        \"supplier_id\": supplier_ids[strip(row['Supplier'])], \n",
    "        \"location_id\": 1, # 1 is unknown\n",
    "        \"archived\": False,\n",
    "        \"warranty_months\": None,\n",
    "        \"depreciate\": False,\n",
    "        \"requestable\": True,\n",
    "        \"rtd_location_id\": None,\n",
    "        \"_snipeit_bdf_8\": row['BDF'],\n",
    "        \"_snipeit_bdf_cost_10\": row['BDF Cost'],\n",
    "        \"_snipeit_condition_9\": row['Condition'],\n",
    "        \"_snipeit_date_used_14\": row['Date Used'],\n",
    "        \"_snipeit_dryness_3\": row['Dryness'],\n",
    "        \"_snipeit_dryness_today_13\": row['Dryness Today'],\n",
    "        \"_snipeit_freight_11\": row['Freight Cost'],\n",
    "        \"_snipeit_grade_2\": row['Grade'],\n",
    "        \"_snipeit_height_5\": row['Height'],\n",
    "        \"_snipeit_length_7\": row['Length'],\n",
    "        \"_snipeit_markup_12\": row['Markup'],\n",
    "        \"_snipeit_project_15\": row['Project'],\n",
    "        \"_snipeit_width_4\": row['Width'],\n",
    "        \"order_number\": row['Order'],\n",
    "        \"book_value\": row['Sell'],\n",
    "        \"purchase_cost\": row['Value'],\n",
    "        \"purchase_date\": formatDate(row['Date']),\n",
    "    }\n",
    "    #strip whitespace from values\n",
    "    cleanDict =  {k: strip(v) for k, v in d.items()}\n",
    "    return cleanDict\n",
    "\n",
    "def getID(tag):\n",
    "    try:\n",
    "        A = snipeit.Assets()\n",
    "        return A.getID(server, token, tag)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def uploadAssetIfNotExist(asset,update=False):\n",
    "    tag = asset['asset_tag']\n",
    "    A = snipeit.Assets()\n",
    "    existing_id = getID(tag)\n",
    "    # pp.pprint(asset)\n",
    "    try:\n",
    "        if existing_id is None:\n",
    "            r = A.create(server, token, json.dumps(asset))\n",
    "            if 'error' in r:\n",
    "                print(f'uploading {tag} status error')\n",
    "                print(r)\n",
    "                r = json.loads(r)\n",
    "                print(f'{tag} error msg = ' + r[\"messages\"])\n",
    "            else:\n",
    "                print(f'{tag} uploaded ok')\n",
    "              \n",
    "            # \n",
    "            # r = A.create(server, token, json.dumps(asset))\n",
    "            # print(r)\n",
    "        else:\n",
    "            if(update):\n",
    "                r = A.updateDevice(server, token, str(existing_id) , json.dumps(asset))\n",
    "                if r:\n",
    "                    print(f'{tag} updated ok')\n",
    "            else:\n",
    "                print(f'{tag} exists, skipping upload')\n",
    "    except:\n",
    "        print(f'Exception uploading {tag} ')\n",
    "\n",
    "\n",
    "        \n",
    "def getJson(tag):\n",
    "    existing_id = getID(tag)\n",
    "    A = snipeit.Assets()\n",
    "    results = A.getDetailsByID(server, token, existing_id)\n",
    "    jsonData = json.loads((results).decode('utf-8').replace(\"'\",'\"'))\n",
    "    pp.pprint(jsonData)\n",
    "\n",
    "\n",
    "getJson('RMT 221001 0067')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': 'https://sawpit.app/uploads/maps/H6.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/E3.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/GA.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/H6.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/CH.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/CA.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/E6.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/HI.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/HF.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/CH.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n",
      "{'image': 'https://sawpit.app/uploads/maps/E6.jpg', '_snipeit_lastgpsping_16': '@39.9898241,-105.0751819'}\n",
      "b'{\"message\":\"The given data was invalid.\",\"errors\":{\"image\":[\"The image must be a file of type: png, gif, jpg, jpeg, svg, bmp, svg+xml, webp.\"]}}'\n"
     ]
    }
   ],
   "source": [
    "#this cell will upload fake maps and gps data\n",
    "\n",
    "#root@limbertimber:/var/www/html/snipeit/public/uploads/assets# ls -la asset-image-1092-OYQSyNFi3U.jpg\n",
    "#-rw-r--r-- 1 www-data www-data 94952 Aug 19 15:12 asset-image-1092-OYQSyNFi3U.jpg\n",
    "\n",
    "\n",
    "import random\n",
    "import requests\n",
    "\n",
    "def getRandMapImg():\n",
    "    mapGrids=\"B4,C1,C6,C7,C8,CA,CG,CH,D2,D3,D4,D5,E2,E3,E4,E5,E6,E9,EC,G5,G8,GA,GB,H1,H6,H7,H8,H9,HA,HB,HC,HD,HE,HF,HG,HL,HI,HH,HJ\".split(',')\n",
    "    grid = random.choice(mapGrids)\n",
    "    fn = f\"https://sawpit.app/uploads/maps/{grid}.jpg\"\n",
    "    #pscp -r G:\\work\\snipe-it\\rmjImport\\maps root@sawpit.app:/var/www/html/snipeit/public/uploads\n",
    "    #chmod -R 644 /var/www/html/snipeit/public/uploads/maps\n",
    "    #chown -R www-data:www-data /var/www/html/snipeit/public/uploads/maps\n",
    "    return fn\n",
    "\n",
    "def setRandomMapImg(tag):\n",
    "    #TODO: set better gps cords\n",
    "    existing_id = getID(tag)\n",
    "    asset = {\n",
    "        'image':getRandMapImg(),\n",
    "        '_snipeit_lastgpsping_16':'@39.9898241,-105.0751819'\n",
    "        }\n",
    "    A = snipeit.Assets()\n",
    "    print(asset)\n",
    "    results = updateDevice(str(existing_id) , json.dumps(asset))\n",
    "    print(results)\n",
    "\n",
    "def updateDevice(DeviceID, payload):\n",
    "    url = server + '/api/v1/hardware/' + DeviceID\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": 'Bearer ' + token,\n",
    "        \"content-type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    results = requests.patch(url, headers=headers, data=payload)\n",
    "    return results.content\n",
    "\n",
    "InventoryCSVfn = 'Master Inventory - RMJC 4-15-2023 - Inventory Master List.csv'\n",
    "\n",
    "skiprows = 0\n",
    "with open(InventoryCSVfn, newline='') as csvfile:\n",
    "    sumRegex = re.compile(r\"(\\w+) - (\\w+) - ([0123456789.x]+)\")\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rowcount = 0\n",
    "    for row in reader:\n",
    "        rowcount+=1\n",
    "        if rowcount < skiprows:\n",
    "            continue\n",
    "\n",
    "        if(len(row['SRL_OLD']) < 3):\n",
    "            print(f\"Row {rowcount} is missing SRL_OLD, skipping it\")\n",
    "            continue\n",
    "        summaryMatch = sumRegex.match(row['Summary Name'])\n",
    "        if(summaryMatch is None):\n",
    "            print(f\"Row {rowcount} has bad summary {row['Summary Name']}, skipping it\")\n",
    "            continue\n",
    "        setRandomMapImg(row['SRL_OLD'])\n",
    "        if rowcount > 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell will do the upload\n",
    "\n",
    "InventoryCSVfn = 'Master Inventory - RMJC 4-15-2023 - Inventory Master List.csv'\n",
    "\n",
    "#TODO: strip whitespace from column names\n",
    "skiprows = 0\n",
    "with open(InventoryCSVfn, newline='') as csvfile:\n",
    "    sumRegex = re.compile(r\"(\\w+) - (\\w+) - ([0123456789.x]+)\")\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rowcount = 0\n",
    "    for row in reader:\n",
    "        rowcount+=1\n",
    "        if rowcount < skiprows:\n",
    "            continue\n",
    "\n",
    "        if(len(row['SRL_OLD']) < 3):\n",
    "            print(f\"Row {rowcount} is missing SRL_OLD, skipping it\")\n",
    "            continue\n",
    "        summaryMatch = sumRegex.match(row['Summary Name'])\n",
    "        if(summaryMatch is None):\n",
    "            print(f\"Row {rowcount} has bad summary {row['Summary Name']}, skipping it\")\n",
    "            continue\n",
    "        asset = csvToAsset(row)\n",
    "        uploadAssetIfNotExist(asset)\n",
    "        if rowcount > 1000:\n",
    "            break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print first 5 assests\n",
    "A = snipeit.Assets()\n",
    "a = json.loads(A.get(server, token, 5)) # With a limit of results\n",
    "pp.pprint(a['rows'][3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
